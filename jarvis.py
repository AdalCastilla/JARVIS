# -*- coding: utf-8 -*-
"""Jarvis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1biZj1P7tUpuxIoo4FucEMOgmaVl6Dt6H
"""

!pip install -q tensorflow scikit-learn pandas numpy matplotlib

import pandas as pd
import numpy as np
import pickle
from google.colab import files
from tqdm.notebook import tqdm
from sklearn.feature_extraction.text import TfidfVectorizer
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

# Configuración
TOTAL_SAMPLES = 500_000  # Medio millón
MAX_FEATURES = 5000      # 5k palabras
CHUNK_SIZE = 30_000      # Carga por partes

# 1. Cargar datos en pequeños chunks
print("Cargando datos")
with open('/content/training.1600000.processed.noemoticon.csv', 'r', encoding='latin-1') as f:
    total_lines = sum(1 for _ in f) - 1

samples_per_chunk = max(1, int(TOTAL_SAMPLES / (total_lines / CHUNK_SIZE)))

chunks = pd.read_csv('/content/training.1600000.processed.noemoticon.csv',
                     encoding='latin-1',
                     header=None,
                     chunksize=CHUNK_SIZE,
                     usecols=[0, 5],
                     names=['target', 'text'])

sampled_data = []
for chunk in tqdm(chunks, total=int(total_lines/CHUNK_SIZE), desc="Procesando chunks"):
    sampled_chunk = chunk.sample(min(samples_per_chunk, len(chunk)), random_state=42)
    sampled_data.append(sampled_chunk)

df = pd.concat(sampled_data)
df['target'] = df['target'].map({4: 1, 0: 0})

# 2. Vectorización
print(" Vectorizando")
vectorizer = TfidfVectorizer(
    max_features=MAX_FEATURES,
    ngram_range=(1, 1),
    min_df=15,
    max_df=0.85,
    dtype=np.float32
)
X = vectorizer.fit_transform(df['text'])  # Mantener en sparse matrix
y = df['target'].values
del df

# 3. Definir generador de batches
class SparseBatchGenerator(tf.keras.utils.Sequence):
    def __init__(self, X, y, batch_size=64):
        self.X = X
        self.y = y
        self.batch_size = batch_size
        self.indices = np.arange(X.shape[0])

    def __len__(self):
        return int(np.ceil(self.X.shape[0] / self.batch_size))

    def __getitem__(self, idx):
        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]
        X_batch = self.X[batch_indices].toarray()  # Solo convierte batch pequeño
        y_batch = self.y[batch_indices]
        return X_batch, y_batch

# Dividir en entrenamiento y validación manualmente
from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

batch_size = 64
train_gen = SparseBatchGenerator(X_train, y_train, batch_size=batch_size)
val_gen = SparseBatchGenerator(X_val, y_val, batch_size=batch_size)

# 4. Modelo
print("Construyendo modelo")
model = Sequential([
    Dense(128, activation='relu', input_shape=(MAX_FEATURES,)),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# 5. Entrenamiento
print("Entrenando ")
history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=50,
    verbose=1
)

# 6. Guardar
print("Guardando modelos")
model.save('sentiment_model.h5')
with open('tfidf_vectorizer.pkl', 'wb') as f:
    pickle.dump(vectorizer, f)

files.download('sentiment_model.h5')
files.download('tfidf_vectorizer.pkl')

print("¡Entrenamiento completado")

import pickle
from tensorflow.keras.models import load_model

# Cargar el modelo de sentimientos
modelo = load_model('/content/sentiment_model.h5')

# Cargar el vectorizador TF-IDF
with open('/content/tfidf_vectorizer.pkl', 'rb') as file:
    vectorizador = pickle.load(file)

!pip install gTTS

from gtts import gTTS
from IPython.display import Audio, display
import random

def hablar_jarvis(texto):
    tts = gTTS(text=texto, lang='en')
    tts.save("jarvis.mp3")
    display(Audio("jarvis.mp3", autoplay=True))

# Función para predecir el sentimiento
def predecir_sentimiento(texto):
    # Convertir el texto en una matriz de características (como lo hiciste al entrenar el modelo)
    texto_tfidf = vectorizador.transform([texto])

    # Predecir el sentimiento
    prediccion = modelo.predict(texto_tfidf)

    # Convertir la predicción en una respuesta legible

    if prediccion > 0.5:
      respuesta = random.choice([
        "Jarvis : I detect a positive sentiment. Good job, sir.",
        "Jarvis: You seem happy today. That's great, sir",
        "Jarvis: Positive energy detected, sir"
    ])
    else:
      respuesta = random.choice([
        "Jarvis: I sense some negativity. Are you okay, sir?",
        "Jarvis: It sounds like you're not feeling well sir",
        "Jarvis: Negative sentiment detected sir"
    ])


    print("JARVIS:", respuesta)
    hablar_jarvis(respuesta)
    return respuesta

!pip install gradio

import gradio as gr

# Interfaz de usuario
iface = gr.Interface(fn=predecir_sentimiento, inputs="text", outputs="text")

# Lanzar la interfaz
iface.launch()